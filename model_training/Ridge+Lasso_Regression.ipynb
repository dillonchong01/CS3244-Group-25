{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Ridge and Lasso Regression for HDB Resale Price Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Import Required Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Load and Preprocess Data**\n",
        "We drop the 'Town' and 'Address' columns, before splitting the dataset into train-test and applying one-hot encoding to categorical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data\n",
        "df = pd.read_csv('../datasets/Final_ResaleData.csv')\n",
        "df = df.drop(columns=['Town', 'Address'])\n",
        "\n",
        "# Split Dataset into Train (80%) and Test (20%) Sets\n",
        "X = df.drop(columns=['Price'])\n",
        "y = df['Price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing pipeline for categorical features (One-Hot Encoding)\n",
        "categorical_columns = [\"Flat_Type\"]\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)],\n",
        "    remainder='passthrough'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Train Ridge Regression Model**\n",
        "Ridge Regression is a regularized version of Linear Regression that adds L2 penalty to prevent overfitting. We'll use a pipeline with preprocessing and hyperparameter tuning to find the best configuration.\n",
        "\n",
        "Ridge Regression hyperparameters to tune:\n",
        "- 'model__alpha': Regularization strength (higher values = more regularization)\n",
        "\n",
        "After finetuning, the best hyperparameters are:\n",
        "- 'model__alpha': 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_iterations: 3\n",
            "n_required_iterations: 3\n",
            "n_possible_iterations: 3\n",
            "min_resources_: 42573\n",
            "max_resources_: 170294\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 6\n",
            "n_resources: 42573\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/arthurchong/miniconda3/envs/cs3244/lib/python3.11/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.44726e-20): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 3\n",
            "n_resources: 85146\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 2\n",
            "n_resources: 170292\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "Best Ridge Regression Parameters: {'model__alpha': 1}\n"
          ]
        }
      ],
      "source": [
        "# Pipeline for Ridge Regression\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', Ridge())\n",
        "])\n",
        "\n",
        "# Hyperparameter Tuning for Ridge Regression\n",
        "ridge_params = {\n",
        "    'model__alpha': [0, 0.5, 1, 2, 10, 100],\n",
        "    }\n",
        "\n",
        "# HalvingGridSearchCV for Ridge Regression\n",
        "ridge_grid_search = HalvingGridSearchCV(estimator=ridge_pipeline, param_grid=ridge_params, cv=3, factor=2, scoring='neg_mean_squared_error', verbose=1)\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Parameters for Ridge Regression\n",
        "best_ridge_params = ridge_grid_search.best_params_\n",
        "print(f'Best Ridge Regression Parameters: {best_ridge_params}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Evaluate Ridge Regression Model**\n",
        "Evaluation is carried out using RMSE, MAE and R^2 to assess prediction accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression RMSE: 74851.41687980082\n",
            "Ridge Regression MAE: 57887.12240357618\n",
            "Ridge Regression R^2: 0.7993305588235631\n"
          ]
        }
      ],
      "source": [
        "ridge_best_model = ridge_grid_search.best_estimator_\n",
        "y_pred_ridge = ridge_best_model.predict(X_test)\n",
        "\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "print(f\"Ridge Regression RMSE: {rmse_ridge}\")\n",
        "print(f\"Ridge Regression MAE: {mae_ridge}\")\n",
        "print(f\"Ridge Regression R^2: {r2_ridge}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Train Lasso Regression Model**\n",
        "Lasso Regression is a regularized version of Linear Regression that adds L1 penalty to prevent overfitting and perform feature selection. In contrast to Ridge Regression, Lasso Regression can drive some coefficients to zero, therefore effectively removing features that do not contribute to the prediction of the dependent variable, reducing model complexity while not losing much on the model's ability to generalize on unseen data\n",
        "\n",
        "Lasso Regression hyperparameters to tune:\n",
        "- 'model__alpha': Regularization strength (higher values = more regularization, more features removed)\n",
        "\n",
        "After finetuning, the best hyperparameters are:\n",
        "- 'model__alpha': 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_iterations: 3\n",
            "n_required_iterations: 3\n",
            "n_possible_iterations: 3\n",
            "min_resources_: 42573\n",
            "max_resources_: 170294\n",
            "aggressive_elimination: False\n",
            "factor: 2\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 4\n",
            "n_resources: 42573\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/arthurchong/miniconda3/envs/cs3244/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+11, tolerance: 7.871e+10\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 2\n",
            "n_resources: 85146\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 1\n",
            "n_resources: 170292\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Lasso Regression Parameters: {'model__alpha': 1, 'model__max_iter': 5000}\n",
            "\n",
            "Feature selection analysis:\n",
            "Total features: 16\n",
            "Features with non-zero coefficients: 16\n",
            "Features with zero coefficients: 0\n"
          ]
        }
      ],
      "source": [
        "# Pipeline for Lasso Regression\n",
        "\n",
        "lasso_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', Lasso())\n",
        "])\n",
        "\n",
        "# Hyperparameter Tuning for Lasso Regressio\n",
        "lasso_params = {\n",
        "    'model__alpha': [1,5,10,100],\n",
        "    'model__max_iter': [5000], # to ensure convergence\n",
        "}\n",
        "\n",
        "# HalvingGridSearchCV for Lasso Regression\n",
        "lasso_grid_search = HalvingGridSearchCV(estimator=lasso_pipeline, param_grid=lasso_params, cv=3, factor=2, scoring='neg_mean_squared_error', verbose=1)\n",
        "lasso_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Parameters for Lasso Regression\n",
        "best_lasso_params = lasso_grid_search.best_params_\n",
        "print(f'Best Lasso Regression Parameters: {best_lasso_params}')\n",
        "\n",
        "# Check which features were selected (non-zero coefficients)\n",
        "lasso_best_model = lasso_grid_search.best_estimator_\n",
        "feature_names = lasso_best_model.named_steps['preprocessor'].get_feature_names_out()\n",
        "coefficients = lasso_best_model.named_steps['model'].coef_\n",
        "\n",
        "print(f'\\nFeature selection analysis:')\n",
        "print(f'Total features: {len(feature_names)}')\n",
        "print(f'Features with non-zero coefficients: {np.sum(coefficients != 0)}')\n",
        "print(f'Features with zero coefficients: {np.sum(coefficients == 0)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Evaluate Lasso Regression Model**\n",
        "Evaluation is carried out using RMSE, MAE and R^2 to assess prediction accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lasso Regression RMSE: 74851.3232367543\n",
            "Lasso Regression MAE: 57887.580503181474\n",
            "Lasso Regression R^2: 0.7993310609192306\n"
          ]
        }
      ],
      "source": [
        "lasso_best_model = lasso_grid_search.best_estimator_\n",
        "y_pred_lasso = lasso_best_model.predict(X_test)\n",
        "\n",
        "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "print(f\"Lasso Regression RMSE: {rmse_lasso}\")\n",
        "print(f\"Lasso Regression MAE: {mae_lasso}\")\n",
        "print(f\"Lasso Regression R^2: {r2_lasso}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs3244",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
